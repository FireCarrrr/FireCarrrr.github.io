{"meta":{"title":"YUYUYU's Blog","subtitle":null,"description":null,"author":"YUYUYU","url":"https://firecarrrr.github.io","root":"/"},"pages":[{"title":"tags","date":"2019-06-15T11:04:49.000Z","updated":"2019-06-15T11:04:49.928Z","comments":true,"path":"tags/index.html","permalink":"https://firecarrrr.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-06-15T11:05:12.000Z","updated":"2019-06-15T11:05:12.073Z","comments":true,"path":"categories/index.html","permalink":"https://firecarrrr.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"HTTPS与TLS","slug":"TLS","date":"2020-04-22T13:01:08.000Z","updated":"2020-04-22T15:18:21.653Z","comments":true,"path":"2020/04/22/TLS/","link":"","permalink":"https://firecarrrr.github.io/2020/04/22/TLS/","excerpt":"","text":"HTTPSHTTP 是基于明文传输的，不具有安全性。很容易被攻击者截获、更改。HTTPS 协议是基于 SSL/TLS 协议上的安全的传输协议。 如何定义安全？ 机密性：数据是被加密的 完整性：数据是不可篡改的 身份认证：能够确定通信方的身份 机密性的实现对称加密加密和解密使用同一个密钥 对称加密.png 对称加密的问题在于无法解决密钥交换的问题，就是说怎么安全的将密钥传递给对方？ 常见的对称加密算法：AES, ChaCha20等 非对称加密存在公钥（公开）和私钥（严格保密）两个密钥 加密解密过程具有单向性：公钥加密只能用私钥解密，反之亦然 非对称加密.png 常用的非对称加密算法：RSA, ECC等 混合加密对称加密无法解决密钥交换问题，非对称加密很慢 融合两种加密方式优点的解决方案是混合加密 通信开始时，先用非对称加密解决密钥交换问题 拿到密钥后，双方使用对称加密进行通信 混合加密.png 完整性的实现摘要算法就是用一个 hash 函数，把数据压缩成一个固定长度、独一无二的摘要字符串 常用的摘要算法：MD5、SHA-1、SHA-2（TLS 推荐使用） 摘要算法.png 通信一方在发送消息时，也发送消息摘要；通信另一方解密后，再算一次摘要，进行比对。一样就是完整、未经篡改的数据。 身份认证的实现数字签名利用私钥加密摘要就能实现数字签名 因为被私钥加密的摘要只能被对应的公钥解密，这就验证了消息发送者的身份 数字签名.png 数字证书和 CA如何判断公钥的来源？如何防止黑客伪造公钥？ CA(Certificate Authority): 证书认证机构，作为一个第三方，用自己的私钥来给公钥签名。把公钥和相关信息一起加密达成一个包，形成了数字证书。 客户端的”证书管理器“中有”受信任的根证书颁发机构“列表。客户端会根据这张表，查看解开数字证书的公钥是否在列表之中。如果在就用它解开数字证书，如果数字证书中记录的网址与正在浏览的网址不一致，就说明证书可能被冒用，浏览器会发出警告。 TLSSSL 即安全套阶层（Secure Socket Layer）,在 OSI 模型中处于第五层（会话层）。SSL 发展到 v3 时已经被证明了是一个非常好的安全通信协议，于是 IETF 把它改名为 TLS（Transport Layer Security），正式标准化，版本号从 1.0 开始算起，实际上 TLS1.0 就是 SSLv3.1。 抓包 TLS 1.2 连接过程下面抓包百度，看看连接建立过程。开始用 Chrome 访问，Chrome 似乎做了一些神奇的优化？一些包抓不到。用 FireFox 就好了。 TCP 连接建立后，浏览器首先会发送一个 Client Hello 消息。消息包括版本号、支持的密码套件、还有一个随机数。 ClientHello.jpg 服务器收到 Client Hello 后，返回一个 Server Hello。会返回版本号、从密码套件中选择一个、一个随机数。 ServerHello.jpg 可以看出百度选择了用 ECDHE 做密钥交换算法。ECDHE 是 ECC 的一个子算法，基于椭圆曲线离散对数。 服务器把证书发送给客户端。客户端可以解析证书，取出服务器的公钥。 certificate.jpg 服务端发送 Server Key Exchange 消息，发送椭圆曲线的公钥（Server Params），再加上自己的私钥签名。客户端可以验证这个消息来自于服务器。 SKexchange.jpg 发送 Server Hello Done 消息。 ServerHelloDone.png 客户端生成一个椭圆曲线公钥（Client Params），用 Client Key Exchange 消息发送给服务器。 客户端和服务器都拿到了 Client Params、Server Params，用 ECDHE 算法，算出 Pre-Master。黑客即便拿到了前面两个参数也算不出 Pre-Master（why？）。客户端和服务器用 Client Random、Server Random、Pre-Master 生成用于加密会话的主密钥 Master Secret，由于 Pre-Master 是保密的，Master Secret 也是保密的。 客户端发送 Change Cipher Spec。再发送一个 Finished 消息，把之前所有发送的数据做个摘要，再加密发送给对方做个验证。服务器同样发送 Change Cipher Spec 和 finish。双方都验证加密、解密 OK，握手结束。后面就收发被加密的 HTTP 请求和响应。 整体流程： 上面这个过程其实是单向认证的握手过程，只认证了服务器的身份（通过服务器证书），而没有认证客户端的身份。因为单向认证过后已经建立了安全通信，可以通过账号、密码来确认用户身份。 银行的 U 盾就是给用户颁发客户端证书，实现双向认证。","categories":[],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://firecarrrr.github.io/tags/HTTPS/"}]},{"title":"Reactor","slug":"Reactor","date":"2020-04-15T10:51:16.000Z","updated":"2020-04-15T14:21:53.481Z","comments":true,"path":"2020/04/15/Reactor/","link":"","permalink":"https://firecarrrr.github.io/2020/04/15/Reactor/","excerpt":"","text":"Reactor 模式 NIO 这部分一直迷迷糊糊的，想借学 Reactor 这部分的时候来谈一下。 IO所谓I/O就是内存和外部设备之间拷贝数据的过程。以网络 I/O为例，也就是用户程序从网卡读取数据和向网卡写数据的过程。这个过程可以被分为两个步骤： 内核从网卡把数据拷贝到内核缓存 数据从内核读取到用户程序地址空间 各种 I/O 模型的区别在于：实现这两个步骤的方式不一样 同步阻塞 I/O 与 TPCTPC 也就是 Thread Per Connection，就是说服务器在处理客户端请求的时候，为每一个客户端分配一个线程去处理。 tpc.png 这里之所以需要为每一个请求分配单独的线程是因为 read、write 这些调用都是同步阻塞的。如果单线程，一阻塞，系统就没办法响应新的请求了。 TPC 的问题在于，创建线程和线程的上下文切换都是需要代价的。面对海量连接，这种模型是无能为力的。 123456789101112131415161718192021222324252627282930313233public class BIOServer &#123; static class ConnectionHandler extends Thread&#123; private Socket socket; public ConnectionHandler(Socket socket)&#123; this.socket = socket; &#125; @Override public void run() &#123; while (!Thread.currentThread().isInterrupted() &amp;&amp; !socket.isClosed())&#123; // 处理读写事件 &#125; &#125; &#125; public static void main(String[] args) &#123; // 线程池 ExecutorService executor = Executors.newFixedThreadPool(100); try&#123; ServerSocket serverSocket = new ServerSocket(); serverSocket.bind(new InetSocketAddress(9999)); // 主线程循环等待新连接到来 while (true)&#123; Socket socket = serverSocket.accept(); // 把任务提交给线程池 executor.submit(new ConnectionHandler(socket)); &#125; &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; &#125;&#125; Reactor 模式TPC 之所以需要创建那么多线程，是因为在执行那些 I/O 操作的时候，并不知道内核是否已经把数据准备好，只能傻等。 NIO 能够解决这个问题，只需要在 Selector 上注册我们感兴趣的事件（有新连接到来、读就绪、写就绪等）。NIO 能同时监听多个连接，当某条连接上就绪时，操作系统就会通知线程，从阻塞态返回，开始处理。 Reactor 模式就是利用 NIO 的这种 I/O 多路复用的特性来实现的更高性能的单机高并发模型。Reactor 模式又叫做 Dispatcher 模式，即 I/O 多路复用统一监听事件，收到事件后 Dispatch 给某个线程。 Reactor 的核心组件包括 Reactor 和处理资源池，典型的配置方案包括： 单 Reactor / 单线程 单 Reactor / 多线程 多 Reactor / 多线程 单 Reactor / 单线程Redis 就是典型的单 Reactor / 单线程模型 单Reactor/单线程.png 客户端发来请求，Reactor 对象通过 Select 监听到连接事件。收到事件后，如果是建立连接的事件，则交给 Acceptor 处理，Acceptor 通过 accept 接受连接，并创建一个 Handler 处理后续时间。如果不是连接建立时间则调用 Acceptor 中建立的 Handler 来进行响应。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class OneThreadReactor extends Thread&#123; /** * 存储连接和 Handler 之间的关系 */ private HashMap&lt;SocketChannel, ChannelHandler&gt; handlerHashMap = new HashMap&lt;&gt;(); @Override public void run() &#123; try(Selector selector = Selector.open(); ServerSocketChannel serverSocketChannel = ServerSocketChannel.open())&#123; serverSocketChannel.bind(new InetSocketAddress(9999)); // 设置 channel 为非阻塞 serverSocketChannel.configureBlocking(false); // 注册到 selector, 设置关注状态 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while(true) &#123; // 阻塞等待就绪的 channel selector.select(); // 获取所有就绪的 channel Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); // 接受连接并注册 handler if(key.isAcceptable()) &#123; registerHandler((ServerSocketChannel) key.channel(), selector); &#125; // 调用连接对应 Handler 处理读事件 else if(key.isReadable()) &#123; getHandler((SocketChannel) key.channel()).channelReadable(); &#125; iterator.remove(); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /** * 接受连接并绑定处理器 * @param serverSocketChannel */ private void registerHandler(ServerSocketChannel serverSocketChannel, Selector selector)&#123; try&#123; SocketChannel socketChannel = serverSocketChannel.accept(); socketChannel.configureBlocking(false); socketChannel.register(selector, SelectionKey.OP_READ); handlerHashMap.put(socketChannel, new ChannelHandler(socketChannel)); &#125; catch (IOException e)&#123; e.printStackTrace(); &#125; &#125; /** * 获取绑定的 handler * @param socketChannel * @return */ private ChannelHandler getHandler(SocketChannel socketChannel)&#123; return handlerHashMap.get(socketChannel); &#125; public static void main(String[] args) &#123; OneThreadReactor server = new OneThreadReactor(); server.start(); &#125;&#125; 单 Reactor / 单线程模型没有线程的切换，确实效率非常高，但是也有它的局限性。第一是不能利用多核能力。第二是应用场景有限，只适合处理速度非常快的场景，如果处理逻辑里有访问数据库等耗时操作，整个服务器就卡住了。 单 Reactor / 多线程 单Reactor/多线程.png 和单 Reactor / 单线程的区别是，Handler 不会负责业务处理，Handler 通过 read 读取到数据后，会发送给 Processor 进行业务处理。业务处理完成之后，会将结果发给主线程中的 send 将相应结果返回给 client。 多 Reactor / 多线程 多Reactor/多线程.png 父线程只监听连接的建立事件，当出现连接建立事件后 Acceptor 接受连接，并将新连接分配给某个子线程。子线程将监听连接，并创建一个对应的 Handler。当事件发生后，子线程调用 Handler 来做相应。 Ngnix（具体实现上有差异）、Netty 就是采用这种模型。","categories":[{"name":"Java","slug":"Java","permalink":"https://firecarrrr.github.io/categories/Java/"}],"tags":[]},{"title":"MySQL事务隔离和MVCC","slug":"mysql-transaction","date":"2019-08-04T08:25:20.000Z","updated":"2019-08-24T14:44:13.468Z","comments":true,"path":"2019/08/04/mysql-transaction/","link":"","permalink":"https://firecarrrr.github.io/2019/08/04/mysql-transaction/","excerpt":"","text":"MySQL事务隔离和MVCC同样，把最近看的事务和锁的部分总结一下，这部分的确东西蛮多的。 MySQL事务其实事务这东西说白了就是一组操作的集合。我们希望数据库系统能够保证这一组操作数据一致且操作独立。数据一致就是说事务在提交的时候保证事务内的所有操作都能成功完成，并且永久生效。操作独立是说多个同时执行的事务之间应该是相互独立，互不影响的。 用标准一点的说法，还就是老生常谈的ACID，感觉ACID更像是目标吧，真实的系统不一定能实现： 原子性（atomicity）：这个最好理解，就是说一个事务的所有操作是不可分隔的最小工作单元，要么全部成功，要么全部失败。 一致性（consistency）：数据库总是从一个一致性状态转换到另一个一致性状态。在任何时刻，包括数据库正常提供服务的时候，数据库从异常中恢复过来的时候，数据都是一致的，保证不会读到中间状态的数据。每本数据库书里都会举的转账的例子，A转200块给B的这个转账的事务执行后，A的钱少了200，B的钱就一定会多200。数据库不会因为这个事务的执行，出现逻辑上不一致的状况。 隔离性（isolation）：所有事情当出现在并发的场景下都会变得复杂。通常来说，一个事务所做的修改在最终提交之前，对其他事务是不可见的。在真实地数据库系统中，不尽然是这样的，可以通过设置不同的隔离级别（isolation level）来调整不同事务操作对彼此的可见性。 持久性（durability）：一旦事务提交，其所做的修改就会永久保存到数据库中。此时即使系统崩溃，修改的数据也不会丢失。 并不是所有存储引擎都支持事务，比如MyISAM就不支持事务。 隔离性与隔离级别当数据库中有多个事务同时执行的时候，如果不加控制，就会出现各种各样的问题： 脏读（dirty read）：当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中的时候，另一个事务也访问了这个数据（脏数据）。 不可重复读（non-repeatable read）：是指在一个事务中，多次读同一个数据。两次读取之间，另一个事务修改了数据，造成第一个事务两次读取数据不一致的情况。 幻读（phantom read）：当保证了可重复读后，事务进行过程中查询的结果都是事务开始时的状态。但是如果另一个事务提交了数据，本事务再更新时，就可能会出现错误，就好像之前读到的数据是“鬼影”一样的幻觉似的。比如，第一个事务对一个表中的数据进行了修改或读取，这种修改或读取涉及到表中所有的数据行。同时，第二个事务向表中插入了一行新数据，就会发生第一个事务发现有行没有被修改的情况。 为了解决这些问题，就有了隔离级别的概念，SQL的标准隔离级别有： 读未提交（read uncommitted）：一个事务还没提交时，它做的变更就能被其它事务看到（这不就相当于没隔离吗），所有的问题都可能发生。 读提交（read committed）：一个事务提交之后，它做的变更才能被其它事务看到。读提交可以解决脏读的问题。 可重复读（repeatable read）：一个事务在执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。可重复读解决了脏读和不可重复读的问题但是没有解决幻读的问题。可重复读是MySQL的默认事务隔离级别。 串行化（serializable）：强制让事务串行执行，最高的隔离级别。 随着隔离级别的提升，出现并发问题的可能性在减小，可是并发性能也在降低。很多时候都是个权衡的问题。 多版本并发控制——MVCCMVCC是一种提高并发的技术。在最早的数据库系统中，只有读读之间可以并发，读写，写读，写写都是要阻塞的。引入MVCC之后，只有写写之间是相互阻塞的，其它三种操作都可以并行，大幅提高了InnoDB的并发度。在多事务环境下，对数据读写在不加读写锁的情况下实现互补干扰，从而实现了数据库的隔离性。 MVCC的实现Undo Logundo log主要用于存放数据被修改前的值。undo log分为两类，一种是INSERT_UNDO，记录插入的唯一键值；一种是UPDATE_UNDO，包括UPDATE及DELETE操作，记录修改的唯一键值以及old column记录。undo log主要由两个作用： 事务回滚 MVCC多版本控制 InnoDB以聚簇索引的方式存储数据，MySQL默认为每个索引添加了4个隐藏的字段。 其中 DB_ROLL_PTR：是undo log的指针，用于记录之前的历史数据在undo log中的位置。undo log中的历史数据行中的DB_ROLL_PTR指向的是上一次修改的行的undo log。这样多次更新后，回滚指针会把不同的版本的记录串在一起。 DB_ROW_ID：是如果没有定义主键和合适的键做主键的时候，MySQL自己生成的一个隐藏的主键。 DB_TRX_ID：是最近更改改行数据的事务ID。 DELETE_BIT：是索引删除标志，如果DB删除了一条数据，是优先通知索引将这个标志位设置为1，然后通过清除线程去异步删除真实的数据 索引隐藏字段.png 整个innoDB的MVCC机制都是通过DB_ROLL_PTR和DB_TRX_ID这两个字段实现的。 Read View由于undo log的存在，数据的多个版本得以保存。这就给事务隔离的实现创造了条件，对于RR和RC隔离级别的事务，对数据进行访问之前都需要对数据的可见性进行判断，也就是说需要判断当前事务是否能看到这一行数据，看到的应该是哪个版本的数据。这些功能的实现依赖于Read View对象。 首先，当一个事务开始的时候，会将当前数据库中正在活跃的所有事务（执行begin，但是还没有commit的事务）保存到一个叫做trx_sys的事务链表中，事务链表中保存的都是未提交的事务，当事务提交之后会从中删除。 活跃事务链表.png Read View的初始化相当于给当前的trx_sys 打一个快照。 活跃事务链表(trx_sys)中事务id最大的值被赋值给m_low_limit_id。 活跃事务链表中第一个值(也就是事务id最小)被赋值给m_up_limit_id。 m_ids 为事务链表。 12345678910111213// readview 初始化// m_low_limit_id = trx_sys-&gt;max_trx_id; // m_up_limit_id = !m_ids.empty() ? m_ids.front() : m_low_limit_id;ReadView::ReadView() : m_low_limit_id(), m_up_limit_id(), m_creator_trx_id(), m_ids(), m_low_limit_no()&#123; ut_d(::memset(&amp;m_view_list, 0x0, sizeof(m_view_list)));&#125; 通过这个Read View，事务就可以根据查询到的所有记录的DB_TRX_ID来匹配是否能看见该记录。 当检索到的数据的事务ID(数据事务ID &lt; m_up_limit_id) 小于事务链表中的最小值表示这个数据在当前事务开启前就已经被其他事务修改过了,所以是可见的。 当检索到的数据的事务ID(数据事务ID = m_creator_trx_id) 表示是当前事务自己修改的数据。 当检索到的数据的事务ID(数据事务ID &gt;= m_low_limit_id) 大于事务链表中的最大值表示这个数据在当前事务开启之前又被其他的事务修改过,那么就是不可见的。 如果事务ID落在(m_up_limit_id,m_low_limit_id)，需要在活跃读写事务数组查找事务ID是否存在，如果存在，记录对于当前read view是不可见的。 如果记录对于view不可见，需要通过记录的DB_ROLL_PTR指针遍历history list构造当前view可见版本数据。 上面基本上是对于聚簇索引的情况，对于二级索引，在二级索引页中存储了更新当前页的最大事务ID，如果该事务ID大于read view中的m_up_limit_id，那么就需要回聚簇索引判断记录可见性。 RR隔离级别（除了Gap锁之外）和RC隔离级别的差别是创建read view的时机不同。RR隔离级别是在事务开始时刻，确切地说是第一个读操作创建read view的；RC隔离级别是在语句开始时刻创建read view的。 undo log什么时候会被删除呢？ 当该undo log关联的事务没有出现在其他事务的read view中时(事务已提交，且没有其他事务依赖当前事务)，那么InnoDB引擎的后台清除线程(purge线程)会进行遍历删除undo log操作。 因此长事务会导致数据库中存在大量的undo log，占用大量的存储空间。所以应该尽量避免长事务。 总结一个月一篇的速度真的是醉了。。。未完待续","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://firecarrrr.github.io/categories/MySQL/"}],"tags":[]},{"title":"MySQL索引（一）","slug":"mysql-index","date":"2019-07-20T09:11:18.000Z","updated":"2019-07-20T09:20:21.078Z","comments":true,"path":"2019/07/20/mysql-index/","link":"","permalink":"https://firecarrrr.github.io/2019/07/20/mysql-index/","excerpt":"","text":"MySQL索引最近在看数据库索引相关的内容，想写成blog，一来整理一下笔记，二来整理一下思路。 索引的目的是加快数据访问的速度，要实现这个目的需要用到一些高效的数据结构。索引是在存储引擎层实现的，不同的存储引擎可能采用不同的实现方式，用到的数据结构也不尽相同。 索引的数据结构基础B-Tree和B+ TreeMySQL的默认存储引擎InnoDB使用B+ Tree来实现索引，B+ Tree是B-Tree的一个变种，基本上大部分存储引擎都是使用B-Tree类的数据结构来实现索引的。 为什么要用B-Tree或者B-Tree产生的动机是什么？ B-Tree本质上是二叉搜索树的一个推广，每一个B-Tree内部节点x有x.n个关键字，这x.n个关键字从小到大依次排列，把关键字分成了x.n+1个区间，那么x就有x.n+1个孩子节点分别存储这些区间范围内的关键字。由于n的数值可以很大，所以B-Tree的树高可以很低，树高低就意味着找到目标需要的随机IO次数少。n的值取多少合适呢？ 我们存储在数据库里的数据，是存储在磁盘上的（也有可能是SSD啦，不过很贵吧），磁盘作为一种依靠磁臂在不同磁道和扇区之间机械运动读取数据的存储装置，与内存和CPU相比就很慢。要加快数据的访问速度那就要减少磁盘IO的次数。磁盘本身存储数据的最小单位是扇区（一般为512 byte），而操作系统的文件系统不是以扇区为单位来读取磁盘的，因为这太慢了，所以有了block（块）的概念，它是一个块一个块的读取的，如果要读取的数据超过一块就会触发多次IO，一个块的大小一般是4K byte。 一个B-Tree算法的运行时间主要由它执行磁盘读写的时间决定，所以，一个B-Tree节点的大小通常和一个完整的块的大小一样大。因此，磁盘块的大小限制了B-Tree节点可以含有的孩子个数。 B+ Tree是B-Tree的一个常见变种，B+Tree把所有的卫星数据（除作为键值外的其他数据）都存储在叶子节点里，也就是说非叶节点只存储键值和孩子指针，并且叶子节点之间用指针连接。 B-Tree由于它的有序性，所以增删节点，维护起来会耗费额外的资源 所以索引会提高查询效率，但是会降低写入和删除的效率 Hash表hash表没啥可说的，key-value存储方式。需要注意的是，由于hash索引不会按键值顺序存储，所以hash索引只适用于等值查询的场景，做区间查询会很慢，也没法做部分匹配。 索引的细节下面关于索引的讨论基本上都是针对于MySQL默认存储引擎InnoDB而言的。 聚簇索引与二级索引对于InnoDB而言，聚簇索引其实就是主键索引，在索引的叶子节点中，存储了包含全部数据的数据行。“聚簇”的意思是说数据行和相邻键值的数据行紧凑的存储在一起（并非一直成立）。 聚簇索引的实现同样依赖于存储引擎，并非所有存储引擎都支持聚簇索引。聚簇索引的优点显而易见，聚簇索引可以最大限度的提高IO密集型应用的性能。但是这种使用这种精巧的数据结构存储数据都会面临维护上的开销。对于聚簇索引来说： 插入新数据行的速度严重依赖于插入顺序。按照主键顺序插入到InnoDB表中速度肯定是最快的，非顺序插入不仅慢而且会导致很多磁盘碎片的产生。所以一般尽量用自增主键做主键值，这样在性能上和存储空间上都有优势。 更新主键的代价很大。因为是数据行按主键顺序紧密存储的，所以更新主键就会带来数据行的移动。 插入新行（乱序）、主键更新需要移动行时，都可能面临“页分裂（page split）”问题。当需要把一行插入到一个已满页面的时候，存储引擎会把这个页分裂成两个页来容纳这个行，页分裂操作会导致占用更多磁盘空间，空间利用率降低。 聚簇索引会让全表扫描变慢，尤其是行比较稀疏的时候，或者由于页分裂导致数据存储不连续的时候。这应该是和把所有数据行直接连续存储相比而言的。 二级索引就是指非主键索引，二级索引的叶子节点中除了存储索引列的值之外，还存储了对应行的主键值。这是与MyISAM存储引擎的一个明显的不同，MyISAM索引的叶子节点中存储的时指向数据行的行指针（MyISAM存储引擎按照数据的插入顺序，将数据行存储在磁盘上）。 InnoDB这种存储主键的方式带来了一个显而易见的好处就是减少了出现行移动或者数据页分裂时二级索引的维护工作。也带来了一个显而易见的坏处就是使用二级索引查询索引不能覆盖的列信息时，需要再到主键索引表回表查询一次。 innoDB和MyISAM索引.png 索引覆盖上面说了，二级索引的叶子节点中只存放索引列的值和主键ID，对于非索引列的查找需要回表。这会带来额外的开销。索引覆盖就是说能不能让索引把查找的target字段全部给包含了。 当发起一个索引覆盖的查询时，EXPLAIN的Extra列可以看到”Using index”信息。 explain.png 最左前缀原则在联合索引中，索引列的顺序对索引的利用率和性能上是有影响的。在一个多列B-Tree索引中，索引列的顺序决定了排序的顺序，越靠左的列排序的优先级越高，也就是说，会先按照第一列排序，在按照第二列排序，以此类推。与此同时，在索引匹配时，是从左往右匹配的。 所以在建立一个多列的联合索引时应该如何安排索引列的顺序呢？ 最重要的原则就是如果通过调整顺序，可以少维护一个索引，那么这个顺序就是需要优先考虑的。评估的标准就是索引的复用能力。因为支持最左前缀，所以有了(a,b)这个联合索引之后，就不需要在a上建立索引了。 还有就是考虑空间占用的问题，假如需(name, age)的联合索引，和name和age单独的索引。因为name比age大，所以应该建立(name, age)这个顺序的索引。 索引下推假设现在有(name,age)联合索引，现在有一个需求：检索出表中名字第一个字是张，而且年龄是10岁的所有男孩 SQL语句如下： 1select * from tuser where name like '张 %' and age=10 and ismale=1; 在这条语句执行时，根据最左前缀匹配原则，这条语句在搜索树的时候只能用到”张“，找到第一个满足条件的记录 ID3。 在MySQL 5.6之前，只能从ID3开始一个个回表，到主键索引上找到数据行，再对比字段值。 索引下推1.jpg 在MySQL 5.6引入了索引下推优化(index condition pushdown)，可以再索引遍历过程中，对索引包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表的次数。 索引下推2.png 总结关于索引的东西还有很多，这篇只是一些非常基础的内容。这篇blog拖了好久了，因为这段时间屁事儿太多了，真的很烦。关于索引的坑以后继续填。","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://firecarrrr.github.io/categories/MySQL/"}],"tags":[]},{"title":"终于搭好了","slug":"终于搭好了","date":"2019-06-15T08:48:18.332Z","updated":"2019-07-20T08:32:58.136Z","comments":true,"path":"2019/06/15/终于搭好了/","link":"","permalink":"https://firecarrrr.github.io/2019/06/15/终于搭好了/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"Java","slug":"Java","permalink":"https://firecarrrr.github.io/categories/Java/"}],"tags":[]}]}